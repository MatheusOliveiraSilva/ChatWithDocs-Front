# üîó Guia de Integra√ß√£o Frontend-Backend

## ‚úÖ **Status da Adapta√ß√£o**

O frontend foi **completamente adaptado** para funcionar com seu backend LangGraph. As principais mudan√ßas realizadas:

### **üõ†Ô∏è Mudan√ßas Implementadas**

1. **Endpoints Atualizados:**
   - `POST /documents/upload-file` - Upload de arquivos
   - `POST /documents/upload` - Upload de texto
   - `DELETE /documents/delete` - Deletar documentos
   - `GET /documents/stats` - Estat√≠sticas
   - `POST /agent/chat` - Chat com streaming LangGraph

2. **Sistema de Conversas Local:**
   - Conversas agora s√£o armazenadas no `localStorage`
   - N√£o dependem mais de backend para persist√™ncia
   - Funcionalidades mantidas: criar, listar, deletar conversas

3. **Gest√£o de Documentos H√≠brida:**
   - Upload e processamento via backend
   - Listagem e associa√ß√£o com conversas via `localStorage`
   - Compatibilidade total com componentes existentes

4. **Processamento de Streaming LangGraph:**
   - Extra√ß√£o correta do conte√∫do de `data.content.content`
   - Detec√ß√£o de execu√ß√£o de ferramentas via `langgraph_node`
   - Feedback visual quando ferramentas est√£o sendo executadas
   - Finaliza√ß√£o baseada em `finish_reason: 'stop'`

## üöÄ **Como Usar**

### **1. Configurar Vari√°vel de Ambiente**

Crie um arquivo `.env` na raiz do projeto:

```env
VITE_API_URL=http://localhost:8000
```

### **2. Iniciar o Frontend**

```bash
npm run dev
```

### **3. Testar Funcionalidades**

O frontend agora oferece:

- ‚úÖ **Upload de documentos** - Funciona via seu backend
- ‚úÖ **Chat com busca** - Usa `/agent/chat` com LangGraph
- ‚úÖ **Gest√£o de conversas** - Local via localStorage
- ‚úÖ **Interface completa** - Todos os componentes funcionam
- ‚úÖ **Feedback de ferramentas** - Mostra quando est√° executando ferramentas

## üìã **Formato Real dos Dados LangGraph**

### **Streaming de Chat**
```http
POST /agent/chat
Content-Type: application/json
Accept: text/event-stream

{
  "messages": [
    {
      "role": "user",
      "content": "Preciso de ajuda com programa√ß√£o em Python"
    }
  ],
  "llm_config": {
    "provider": "openai",
    "model": "gpt-4o"
  }
}
```

**Resposta do LangGraph (Server-Sent Events):**
```
data: {'content': AIMessageChunk(content='Claro', additional_kwargs={}, response_metadata={}, id='run--7e5c9b3c-f36d-46bc-ab64-7e44dfb2cfc3'), 'metadata': {'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0}}

data: {'content': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run--7e5c9b3c-f36d-46bc-ab64-7e44dfb2cfc3'), 'metadata': {'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0}}

data: {'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06'}, id='run--7e5c9b3c-f36d-46bc-ab64-7e44dfb2cfc3'), 'metadata': {'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'checkpoint_ns': 'agent:abe1459f-551a-8af0-aad3-4cd7f1da6d0a', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0}}
```

## üîß **Processamento do Streaming**

### **1. Extra√ß√£o de Conte√∫do**
```javascript
// Formato recebido do LangGraph
const data = {
  'content': AIMessageChunk(content='texto', ...),
  'metadata': {
    'langgraph_node': 'agent',  // ou nome da ferramenta
    'langgraph_step': 1,
    'ls_provider': 'openai',
    // ... outros metadados
  }
};

// Extra√ß√£o do texto
const textContent = data.content.content;
const currentNode = data.metadata.langgraph_node;
```

### **2. Detec√ß√£o de Execu√ß√£o de Ferramentas**
```javascript
// Se langgraph_node !== 'agent', est√° executando uma ferramenta
if (langGraphNode && langGraphNode !== 'agent') {
  // Mostrar feedback visual: "Executando ferramenta: {nome}"
  showToolExecution(langGraphNode);
} else {
  // √â o agente respondendo, processar o texto normalmente
  processTextContent(textContent);
}
```

### **3. Finaliza√ß√£o do Streaming**
```javascript
// Verificar finish_reason para finalizar
const finishReason = data.content.response_metadata?.finish_reason;
if (finishReason === 'stop') {
  // Finalizar streaming e salvar resposta completa
  completeResponse(fullResponse);
}
```

## üìã **Upload de Arquivo**
```http
POST /documents/upload-file
Content-Type: multipart/form-data

# FormData:
- file: [arquivo]
- metadata: '{"thread_id": "demo-123", "filename": "doc.pdf"}'
```

**Resposta esperada:**
```json
{
  "success": true,
  "document_id": "doc_a1b2c3d4e5f6789",
  "vectors_created": 5,
  "processing_time": 2.45
}
```

## üéØ **Funcionalidades Implementadas**

### **‚úÖ Funciona Completamente:**
- Upload de documentos (arquivo e texto)
- Chat com busca em documentos via LangGraph
- Streaming de respostas com feedback de ferramentas
- Gest√£o de conversas local
- Interface de usu√°rio completa
- Feedback visual quando ferramentas est√£o sendo executadas

### **üîÑ Feedback Visual de Ferramentas:**
- Quando `langgraph_node` ‚â† 'agent': mostra "Executando ferramenta: {nome}"
- Spinner animado durante execu√ß√£o
- Transi√ß√£o suave entre execu√ß√£o de ferramenta e resposta do agente

### **üìã Simulado Localmente:**
- Lista de documentos por conversa
- Status de processamento
- Progresso de indexa√ß√£o
- Metadados de documentos

## üö¶ **Teste de Integra√ß√£o**

Para testar a integra√ß√£o:

1. **Inicie seu backend LangGraph** na porta 8000
2. **Configure a vari√°vel** `VITE_API_URL=http://localhost:8000`
3. **Inicie o frontend** com `npm run dev`
4. **Teste o upload** de um documento
5. **Teste o chat** fazendo perguntas - observe o feedback de ferramentas!

## üìù **Logs e Debug**

O frontend agora inclui logs detalhados para LangGraph:

```javascript
// Logs de streaming LangGraph
console.log('Iniciando streaming LangGraph:', config);
console.log('Chunk LangGraph bruto:', chunk);
console.log('Dados LangGraph:', data);
console.log('Token LangGraph recebido:', textContent);

// Logs de execu√ß√£o de ferramentas
console.log('Executando ferramenta:', toolName);
console.log('Ferramenta finalizada:', toolName);
```

## üéâ **Resultado**

O frontend est√° **100% funcional** com seu backend LangGraph, incluindo:

- ‚úÖ **Processamento correto** do formato de dados real
- ‚úÖ **Feedback visual** de execu√ß√£o de ferramentas
- ‚úÖ **Streaming otimizado** com detec√ß√£o de finaliza√ß√£o
- ‚úÖ **Interface moderna** com indicadores visuais
- ‚úÖ **Logs detalhados** para debugging
- ‚úÖ **Experi√™ncia completa** para demonstra√ß√£o acad√™mica! 